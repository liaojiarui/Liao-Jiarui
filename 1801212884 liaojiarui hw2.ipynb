{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month    MEI     CO2      CH4      N2O   CFC-11   CFC-12  \\\n",
      "0    1983      5  2.556  345.96  1638.59  303.677  191.324  350.113   \n",
      "1    1983      6  2.167  345.52  1633.71  303.746  192.057  351.848   \n",
      "2    1983      7  1.741  344.15  1633.22  303.795  192.818  353.725   \n",
      "3    1983      8  1.130  342.25  1631.35  303.839  193.602  355.633   \n",
      "4    1983      9  0.428  340.17  1648.40  303.901  194.392  357.465   \n",
      "5    1983     10  0.002  340.30  1663.79  303.970  195.171  359.174   \n",
      "6    1983     11 -0.176  341.53  1658.23  304.032  195.921  360.758   \n",
      "7    1983     12 -0.176  343.07  1654.31  304.082  196.609  362.174   \n",
      "8    1984      1 -0.339  344.05  1658.98  304.130  197.219  363.359   \n",
      "9    1984      2 -0.565  344.77  1656.48  304.194  197.759  364.296   \n",
      "10   1984      3  0.131  345.46  1655.77  304.285  198.249  365.044   \n",
      "11   1984      4  0.331  346.77  1657.68  304.389  198.723  365.692   \n",
      "12   1984      5  0.121  347.55  1649.33  304.489  199.233  366.317   \n",
      "13   1984      6 -0.142  346.98  1634.13  304.593  199.858  367.029   \n",
      "14   1984      7 -0.138  345.55  1629.89  304.722  200.671  367.893   \n",
      "15   1984      8 -0.179  343.20  1643.67  304.871  201.710  368.843   \n",
      "16   1984      9 -0.082  341.35  1663.60  305.021  202.972  369.800   \n",
      "17   1984     10  0.016  341.68  1674.65  305.158  204.407  370.782   \n",
      "18   1984     11 -0.351  343.06  1677.10  305.263  205.893  371.770   \n",
      "19   1984     12 -0.611  344.54  1672.15  305.313  207.308  372.701   \n",
      "20   1985      1 -0.561  345.25  1663.42  305.301  208.537  373.623   \n",
      "21   1985      2 -0.602  346.06  1666.21  305.243  209.543  374.681   \n",
      "22   1985      3 -0.737  347.66  1678.34  305.165  210.368  376.004   \n",
      "23   1985      4 -0.484  348.20  1675.24  305.093  211.111  377.635   \n",
      "24   1985      5 -0.731  348.92  1666.83  305.045  211.823  379.539   \n",
      "25   1985      6 -0.086  348.40  1659.40  305.027  212.512  381.642   \n",
      "26   1985      7 -0.156  346.66  1654.25  305.049  213.165  383.905   \n",
      "27   1985      8 -0.392  344.85  1654.41  305.126  213.803  386.223   \n",
      "28   1985      9 -0.541  343.20  1668.31  305.250  214.501  388.500   \n",
      "29   1985     10 -0.140  343.08  1681.56  305.395  215.327  390.676   \n",
      "..    ...    ...    ...     ...      ...      ...      ...      ...   \n",
      "278  2006      7  0.628  382.38  1765.95  319.872  249.247  539.725   \n",
      "279  2006      8  0.759  380.45  1762.66  319.930  248.981  539.682   \n",
      "280  2006      9  0.793  378.92  1776.04  320.010  248.775  539.566   \n",
      "281  2006     10  0.892  379.16  1789.02  320.125  248.666  539.488   \n",
      "282  2006     11  1.292  380.18  1791.91  320.321  248.605  539.500   \n",
      "283  2006     12  0.951  381.79  1795.04  320.451  248.480  539.377   \n",
      "284  2007      1  0.974  382.93  1799.66  320.561  248.372  539.206   \n",
      "285  2007      2  0.510  383.81  1803.08  320.571  248.264  538.973   \n",
      "286  2007      3  0.074  384.56  1803.10  320.548  247.997  538.811   \n",
      "287  2007      4 -0.049  386.40  1802.11  320.518  247.574  538.586   \n",
      "288  2007      5  0.183  386.58  1795.65  320.445  247.224  538.130   \n",
      "289  2007      6 -0.358  386.05  1781.81  320.332  246.881  537.376   \n",
      "290  2007      7 -0.290  384.49  1771.89  320.349  246.497  537.113   \n",
      "291  2007      8 -0.440  382.00  1779.38  320.471  246.307  537.125   \n",
      "292  2007      9 -1.162  380.90  1794.21  320.618  246.214  537.281   \n",
      "293  2007     10 -1.142  381.14  1802.38  320.855  246.189  537.380   \n",
      "294  2007     11 -1.177  382.42  1803.79  321.062  246.178  537.319   \n",
      "295  2007     12 -1.168  383.89  1805.58  321.217  246.261  537.052   \n",
      "296  2008      1 -1.011  385.44  1809.92  321.328  246.183  536.876   \n",
      "297  2008      2 -1.402  385.73  1803.45  321.345  245.898  536.484   \n",
      "298  2008      3 -1.635  385.97  1792.84  321.295  245.430  535.979   \n",
      "299  2008      4 -0.942  387.16  1792.57  321.354  245.086  535.648   \n",
      "300  2008      5 -0.355  388.50  1796.43  321.420  244.914  535.399   \n",
      "301  2008      6  0.128  387.88  1791.80  321.447  244.676  535.128   \n",
      "302  2008      7  0.003  386.42  1782.93  321.372  244.434  535.026   \n",
      "303  2008      8 -0.266  384.15  1779.88  321.405  244.200  535.072   \n",
      "304  2008      9 -0.643  383.09  1795.08  321.529  244.083  535.048   \n",
      "305  2008     10 -0.780  382.99  1814.18  321.796  244.080  534.927   \n",
      "306  2008     11 -0.621  384.13  1812.37  322.013  244.225  534.906   \n",
      "307  2008     12 -0.666  385.56  1812.88  322.182  244.204  535.005   \n",
      "\n",
      "           TSI  Aerosols   Temp  \n",
      "0    1366.1024    0.0863  0.109  \n",
      "1    1366.1208    0.0794  0.118  \n",
      "2    1366.2850    0.0731  0.137  \n",
      "3    1366.4202    0.0673  0.176  \n",
      "4    1366.2335    0.0619  0.149  \n",
      "5    1366.0589    0.0569  0.093  \n",
      "6    1366.1072    0.0524  0.232  \n",
      "7    1366.0607    0.0486  0.078  \n",
      "8    1365.4261    0.0451  0.089  \n",
      "9    1365.6618    0.0416  0.013  \n",
      "10   1366.1697    0.0383  0.049  \n",
      "11   1365.5660    0.0352 -0.019  \n",
      "12   1365.7783    0.0324  0.065  \n",
      "13   1366.0956    0.0302 -0.016  \n",
      "14   1366.1145    0.0282 -0.024  \n",
      "15   1365.9781    0.0260  0.034  \n",
      "16   1365.8669    0.0239  0.025  \n",
      "17   1365.7869    0.0220 -0.035  \n",
      "18   1365.6802    0.0202 -0.123  \n",
      "19   1365.7617    0.0188 -0.282  \n",
      "20   1365.6082    0.0164 -0.001  \n",
      "21   1365.7085    0.0160 -0.155  \n",
      "22   1365.6570    0.0141 -0.032  \n",
      "23   1365.5120    0.0138 -0.042  \n",
      "24   1365.6366    0.0128  0.001  \n",
      "25   1365.6964    0.0126 -0.049  \n",
      "26   1365.6509    0.0121 -0.042  \n",
      "27   1365.7499    0.0116  0.013  \n",
      "28   1365.6653    0.0102 -0.035  \n",
      "29   1365.5269    0.0101 -0.008  \n",
      "..         ...       ...    ...  \n",
      "278  1365.8212    0.0038  0.456  \n",
      "279  1365.7067    0.0041  0.482  \n",
      "280  1365.8419    0.0043  0.425  \n",
      "281  1365.8270    0.0044  0.472  \n",
      "282  1365.7039    0.0049  0.440  \n",
      "283  1365.7087    0.0054  0.518  \n",
      "284  1365.7173    0.0054  0.601  \n",
      "285  1365.7145    0.0051  0.498  \n",
      "286  1365.7544    0.0045  0.435  \n",
      "287  1365.7228    0.0045  0.466  \n",
      "288  1365.6932    0.0041  0.372  \n",
      "289  1365.7616    0.0040  0.382  \n",
      "290  1365.7506    0.0040  0.394  \n",
      "291  1365.7566    0.0041  0.358  \n",
      "292  1365.7159    0.0042  0.402  \n",
      "293  1365.7388    0.0041  0.362  \n",
      "294  1365.6680    0.0042  0.266  \n",
      "295  1365.6927    0.0040  0.226  \n",
      "296  1365.7163    0.0038  0.074  \n",
      "297  1365.7366    0.0036  0.198  \n",
      "298  1365.6726    0.0034  0.447  \n",
      "299  1365.7146    0.0033  0.278  \n",
      "300  1365.7175    0.0031  0.283  \n",
      "301  1365.6730    0.0031  0.315  \n",
      "302  1365.6720    0.0033  0.406  \n",
      "303  1365.6570    0.0036  0.407  \n",
      "304  1365.6647    0.0043  0.378  \n",
      "305  1365.6759    0.0046  0.440  \n",
      "306  1365.7065    0.0048  0.394  \n",
      "307  1365.6926    0.0046  0.330  \n",
      "\n",
      "[308 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "raw_df=pd.read_csv('climate_change_1.csv')\n",
    "print(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month    MEI     CO2      CH4      N2O   CFC-11   CFC-12  \\\n",
      "284  2007      1  0.974  382.93  1799.66  320.561  248.372  539.206   \n",
      "285  2007      2  0.510  383.81  1803.08  320.571  248.264  538.973   \n",
      "286  2007      3  0.074  384.56  1803.10  320.548  247.997  538.811   \n",
      "287  2007      4 -0.049  386.40  1802.11  320.518  247.574  538.586   \n",
      "288  2007      5  0.183  386.58  1795.65  320.445  247.224  538.130   \n",
      "289  2007      6 -0.358  386.05  1781.81  320.332  246.881  537.376   \n",
      "290  2007      7 -0.290  384.49  1771.89  320.349  246.497  537.113   \n",
      "291  2007      8 -0.440  382.00  1779.38  320.471  246.307  537.125   \n",
      "292  2007      9 -1.162  380.90  1794.21  320.618  246.214  537.281   \n",
      "293  2007     10 -1.142  381.14  1802.38  320.855  246.189  537.380   \n",
      "294  2007     11 -1.177  382.42  1803.79  321.062  246.178  537.319   \n",
      "295  2007     12 -1.168  383.89  1805.58  321.217  246.261  537.052   \n",
      "296  2008      1 -1.011  385.44  1809.92  321.328  246.183  536.876   \n",
      "297  2008      2 -1.402  385.73  1803.45  321.345  245.898  536.484   \n",
      "298  2008      3 -1.635  385.97  1792.84  321.295  245.430  535.979   \n",
      "299  2008      4 -0.942  387.16  1792.57  321.354  245.086  535.648   \n",
      "300  2008      5 -0.355  388.50  1796.43  321.420  244.914  535.399   \n",
      "301  2008      6  0.128  387.88  1791.80  321.447  244.676  535.128   \n",
      "302  2008      7  0.003  386.42  1782.93  321.372  244.434  535.026   \n",
      "303  2008      8 -0.266  384.15  1779.88  321.405  244.200  535.072   \n",
      "304  2008      9 -0.643  383.09  1795.08  321.529  244.083  535.048   \n",
      "305  2008     10 -0.780  382.99  1814.18  321.796  244.080  534.927   \n",
      "306  2008     11 -0.621  384.13  1812.37  322.013  244.225  534.906   \n",
      "307  2008     12 -0.666  385.56  1812.88  322.182  244.204  535.005   \n",
      "\n",
      "           TSI  Aerosols  \n",
      "284  1365.7173    0.0054  \n",
      "285  1365.7145    0.0051  \n",
      "286  1365.7544    0.0045  \n",
      "287  1365.7228    0.0045  \n",
      "288  1365.6932    0.0041  \n",
      "289  1365.7616    0.0040  \n",
      "290  1365.7506    0.0040  \n",
      "291  1365.7566    0.0041  \n",
      "292  1365.7159    0.0042  \n",
      "293  1365.7388    0.0041  \n",
      "294  1365.6680    0.0042  \n",
      "295  1365.6927    0.0040  \n",
      "296  1365.7163    0.0038  \n",
      "297  1365.7366    0.0036  \n",
      "298  1365.6726    0.0034  \n",
      "299  1365.7146    0.0033  \n",
      "300  1365.7175    0.0031  \n",
      "301  1365.6730    0.0031  \n",
      "302  1365.6720    0.0033  \n",
      "303  1365.6570    0.0036  \n",
      "304  1365.6647    0.0043  \n",
      "305  1365.6759    0.0046  \n",
      "306  1365.7065    0.0048  \n",
      "307  1365.6926    0.0046  \n"
     ]
    }
   ],
   "source": [
    "# Split the data into training set\n",
    "X_test=raw_df[raw_df['Year']>2006].iloc[:,:-1]\n",
    "y_test=raw_df[raw_df['Year']>2006].iloc[:,-1]\n",
    "X_train=raw_df[raw_df['Year']<=2006].iloc[:,:-1]\n",
    "y_train=raw_df[raw_df['Year']<=2006].iloc[:,-1]\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the closed form solution\n",
    "def closed_form(X_train,y_train):\n",
    "    return np.dot(np.matmul(np.linalg.inv(np.matmul(X_train.transpose(),X_train)),X_train.transpose()),y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.24887416e-02 -6.16714874e-03  6.48363535e-02  6.46994230e-03\n",
      " -1.57088222e-04  2.29289620e-02 -1.00275979e-02  6.77771347e-03\n",
      "  5.49139594e-02 -1.64648727e+00]\n"
     ]
    }
   ],
   "source": [
    "theta=closed_form(np.array(X_train),np.array(y_train))\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Square of training set:\n",
      "0.7489870281004234\n"
     ]
    }
   ],
   "source": [
    "#Write down the mathematical formula for the linear model \n",
    "Y_fit = np.dot (X_train, theta)\n",
    "\n",
    "#Evaluate the model R2\n",
    "y_fit=np.dot(X_train,theta)\n",
    "y_mean=np.mean(y_train)\n",
    "print(\"R_Square of training set:\")\n",
    "print(np.dot(y_fit-y_mean,y_fit-y_mean)/np.dot(np.array(y_train)-y_mean,np.array(y_train)-y_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Square of test set:\n",
      "0.2616138833227\n"
     ]
    }
   ],
   "source": [
    "y_test_fit=np.dot(X_test,theta)\n",
    "y_test_mean=np.mean(y_test)\n",
    "print(\"R_Square of test set:\")\n",
    "print(np.dot(y_test_fit-y_test_mean,y_test_fit-y_test_mean)/np.dot(np.array(y_test)-y_test_mean,np.array(y_test)-y_test_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_2(X_train,y_train,Lambda):\n",
    "    return np.dot(np.matmul(np.linalg.inv(np.matmul(X_train.transpose(),X_train)-Lambda*np.identity(X_train.shape[1])),X_train.transpose()),y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.68848685e-02 -4.40486101e-03  4.27538087e-02  9.06507354e-03\n",
      "  1.77964222e-04  3.86582613e-03 -9.70260898e-03  5.97524112e-03\n",
      "  3.55660848e-02  3.59229422e-01]\n"
     ]
    }
   ],
   "source": [
    "Lambda=1\n",
    "theta2=closed_form_2(np.array(X_train),np.array(y_train),Lambda)\n",
    "print(theta2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Square of training set:\n",
      "0.7002745349237837\n"
     ]
    }
   ],
   "source": [
    "#Compare the two solutions in problem 1 and problem 2:\n",
    "y_fit=np.dot(X_train,theta2)\n",
    "y_mean=np.mean(y_train)\n",
    "print(\"R_Square of training set:\")\n",
    "print(np.dot(y_fit-y_mean,y_fit-y_mean)/np.dot(np.array(y_train)-y_mean,np.array(y_train)-y_mean))\n",
    "# print(np.array(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Square of test set:\n",
      "0.46464512531827645\n"
     ]
    }
   ],
   "source": [
    "y_test_fit=np.dot(X_test,theta2)\n",
    "y_test_mean=np.mean(y_test)\n",
    "# print(y_average)\n",
    "print(\"R_Square of test set:\")\n",
    "print(np.dot(y_test_fit-y_test_mean,y_test_fit-y_test_mean)/np.dot(np.array(y_test)-y_test_mean,np.array(y_test)-y_test_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda= 0.001\n",
      "\n",
      "R_Square of training set: 0.7495780710535302\n",
      "       0         1         2         3         4        5         6    \\\n",
      "0  0.15375  0.138685  0.121763  0.087065  0.023763 -0.00764 -0.001793   \n",
      "1  0.10900  0.118000  0.137000  0.176000  0.149000  0.09300  0.232000   \n",
      "\n",
      "        7         8         9    ...       274       275       276       277  \\\n",
      "0  0.010186  0.004465  0.009832  ...  0.394054  0.392035  0.437296  0.461777   \n",
      "1  0.078000  0.089000  0.013000  ...  0.380000  0.378000  0.352000  0.442000   \n",
      "\n",
      "        278       279       280       281       282       283  \n",
      "0  0.451102  0.438407  0.432663  0.434633  0.458168  0.442598  \n",
      "1  0.456000  0.482000  0.425000  0.472000  0.440000  0.518000  \n",
      "\n",
      "[2 rows x 284 columns]\n",
      "R_Square of test set: 0.2623254047426737\n",
      "Lambda= 0.01\n",
      "\n",
      "R_Square of training set: 0.7553790551048112\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.150473  0.135805  0.119347  0.084935  0.021256 -0.010494 -0.004415   \n",
      "1  0.109000  0.118000  0.137000  0.176000  0.149000  0.093000  0.232000   \n",
      "\n",
      "        7         8         9    ...       274       275       276       277  \\\n",
      "0  0.007752  0.001656  0.007279  ...  0.392181  0.389482  0.435458  0.460739   \n",
      "1  0.078000  0.089000  0.013000  ...  0.380000  0.378000  0.352000  0.442000   \n",
      "\n",
      "        278       279       280       281       282       283  \n",
      "0  0.450384  0.437928  0.432281  0.434126  0.457837  0.441694  \n",
      "1  0.456000  0.482000  0.425000  0.472000  0.440000  0.518000  \n",
      "\n",
      "[2 rows x 284 columns]\n",
      "R_Square of test set: 0.26989557865532154\n",
      "Lambda= 0.1\n",
      "\n",
      "R_Square of training set: 0.9668693311144463\n",
      "       0         1         2         3         4         5         6    \\\n",
      "0  0.07623  0.070551  0.064583  0.036665 -0.035477 -0.075061 -0.063737   \n",
      "1  0.10900  0.118000  0.137000  0.176000  0.149000  0.093000  0.232000   \n",
      "\n",
      "        7         8        9    ...       274       275      276       277  \\\n",
      "0 -0.047345 -0.061831 -0.05043  ...  0.349914  0.331802  0.39394  0.437306   \n",
      "1  0.078000  0.089000  0.01300  ...  0.380000  0.378000  0.35200  0.442000   \n",
      "\n",
      "        278       279       280       281       282       283  \n",
      "0  0.434195  0.427146  0.423692  0.422701  0.450378  0.421284  \n",
      "1  0.456000  0.482000  0.425000  0.472000  0.440000  0.518000  \n",
      "\n",
      "[2 rows x 284 columns]\n",
      "R_Square of test set: 0.8200829029899867\n",
      "Lambda= 1\n",
      "\n",
      "R_Square of training set: 0.7002745349237837\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.229869  0.205673  0.178147  0.136752  0.081454  0.057668  0.058342   \n",
      "1  0.109000  0.118000  0.137000  0.176000  0.149000  0.093000  0.232000   \n",
      "\n",
      "       7         8         9    ...       274       275       276       277  \\\n",
      "0  0.06616  0.067994  0.067741  ...  0.435917  0.449449  0.478746  0.485091   \n",
      "1  0.07800  0.089000  0.013000  ...  0.380000  0.378000  0.352000  0.442000   \n",
      "\n",
      "        278       279      280       281       282       283  \n",
      "0  0.467036  0.448734  0.44079  0.445645  0.465325  0.462824  \n",
      "1  0.456000  0.482000  0.42500  0.472000  0.440000  0.518000  \n",
      "\n",
      "[2 rows x 284 columns]\n",
      "R_Square of test set: 0.46464512531827645\n",
      "Lambda= 10\n",
      "\n",
      "R_Square of training set: 0.7097751568666681\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.230692  0.207313  0.181261  0.139584  0.077776  0.049918  0.052629   \n",
      "1  0.109000  0.118000  0.137000  0.176000  0.149000  0.093000  0.232000   \n",
      "\n",
      "        7         8         9    ...       274       275       276       277  \\\n",
      "0  0.062035  0.053445  0.056232  ...  0.422326  0.433451  0.468355  0.478405   \n",
      "1  0.078000  0.089000  0.013000  ...  0.380000  0.378000  0.352000  0.442000   \n",
      "\n",
      "        278       279       280       281       282       283  \n",
      "0  0.460765  0.441737  0.434216  0.438785  0.460393  0.456114  \n",
      "1  0.456000  0.482000  0.425000  0.472000  0.440000  0.518000  \n",
      "\n",
      "[2 rows x 284 columns]\n",
      "R_Square of test set: 0.31572868589018216\n"
     ]
    }
   ],
   "source": [
    "Lambda_list = [0.001,0.01,0.1,1,10]\n",
    "for Lambda in Lambda_list:\n",
    "    theta2=closed_form_2(np.array(X_train),np.array(y_train),Lambda)\n",
    "    y_fit=np.dot(X_train,theta2)\n",
    "    y_mean=np.mean(y_train)\n",
    "    print(\"Lambda=\", Lambda)\n",
    "    print()\n",
    "    print(\"R_Square of training set:\", np.dot(y_fit-y_mean,y_fit-y_mean)/np.dot(np.array(y_train)-y_mean,np.array(y_train)-y_mean))\n",
    "    print(pd.DataFrame([y_fit,y_train]))\n",
    "\n",
    "    y_test_fit=np.dot(X_test,theta2)\n",
    "    y_test_mean=np.mean(y_test)\n",
    "    print(\"R_Square of test set:\", np.dot(y_test_fit-y_test_mean,y_test_fit-y_test_mean)/np.dot(np.array(y_test)-y_test_mean,np.array(y_test)-y_test_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.29314705,  1.97010867, -0.49649098, -0.92635987],\n",
       "       [ 5.27732127,  1.56633915, -0.36591643, -0.58403133],\n",
       "       [ 5.21325388,  1.19335413,  0.09768306, -0.19103688],\n",
       "       ...,\n",
       "       [-2.67887217, -0.11573977, -1.68862682,  0.68617089],\n",
       "       [-2.70457373,  0.15983383, -2.17966018,  0.88171843],\n",
       "       [-2.80414419, -0.07066079, -2.08357461,  1.20087782]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# feature normalization (feature scaling)\n",
    "X_scaler = StandardScaler()\n",
    "x = X_scaler.fit_transform(X_train)\n",
    " \n",
    "# PCA: Keep 80% of the information after dimension reduction\n",
    "pca = PCA(n_components=0.8) \n",
    "pca.fit(x)\n",
    "pca.transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train):\n",
    "    mean=np.mean(X_train)\n",
    "    M1=np.max(X_train)\n",
    "    M2=np.min(X_train)\n",
    "    X=(X_train-mean)/(M1-M2)\n",
    "    return X,mean,M1,M2\n",
    "\n",
    "X_train_norm,mean_train,max_train,min_train=normalization(X_train)\n",
    "def gradient_Decent(X_train,y_train,Lambda,alpha):\n",
    "    iters=10000\n",
    "    X=X_train.copy()\n",
    "    X.insert(0,'intercept',np.ones(len(X)))\n",
    "    theta=np.zeros(X.shape[1])\n",
    "    delta=np.matmul(X.T,np.matmul(X,theta)-y_train)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        delta=np.matmul(X.T,np.matmul(X,theta)-y_train)\n",
    "        theta[0]=theta[0]-(alpha/X.shape[0])*(delta[0])\n",
    "        theta[1:]=theta[1:]-(alpha/X.shape[0])*(delta[1:]+Lambda*theta[1:])\n",
    "        \n",
    "    return theta\n",
    "for Lambda in Lambda_list:\n",
    "    \n",
    "    theta2=gradient_decent(X_train_norm,y_train,Lambda,0.1)\n",
    "    y_fit=theta2[0]+np.matmul(X_train_norm,theta2[1:])\n",
    "    y_mean=np.mean(y_train)\n",
    "    print(\"Lambda=\",end=\" \")\n",
    "    print(Lambda)\n",
    "    print(\"R_Square of training set:\",end=\" \")\n",
    "    print(1-np.matmul(y_fit-y_train,y_fit-y_train)/np.matmul(y_train-y_mean,y_train-y_mean),end=\", \")    \n",
    "    y_test_fit=theta2[0]+np.matmul((X_test-mean_train)/(max_train-min_train),theta2[1:])\n",
    "    y_test_mean=np.mean(y_test)\n",
    "    print(\"R_Square of test set:\", 1-np.matmul(y_test_fit-y_test,y_test_fit-y_test)/np.matmul(y_test-y_test_mean,y_test-y_test_mean))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
